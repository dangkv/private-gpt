# ğŸ”’ PrivateGPT - Your Personal AI Assistant

<div align="center">

![PrivateGPT Logo](https://img.shields.io/badge/ğŸ¤–-PrivateGPT-blue?style=for-the-badge)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg?style=for-the-badge)
![License](https://img.shields.io/badge/license-MIT-green.svg?style=for-the-badge)

*Chat with your documents privately, locally, and securely* âœ¨

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸŒŸ What is PrivateGPT?

PrivateGPT transforms your personal documents into an intelligent, conversational AI assistant. Unlike cloud-based solutions, **everything runs locally** on your machine, ensuring your sensitive data never leaves your control.

### ğŸš€ Why PrivateGPT?

- **ğŸ” Complete Privacy**: Your documents never leave your machine
- **ğŸ“š Smart Document Understanding**: Chat with PDFs, Word docs, and text files
- **âš¡ Real-time Responses**: Streaming responses for better user experience
- **ğŸ¯ Context-Aware**: Provides accurate answers based on your documents
- **ğŸ› ï¸ Easy Setup**: Simple installation and intuitive interface

---

## âœ¨ Features

### ğŸ” **Intelligent Document Processing**
- Supports multiple formats: PDF, DOCX, DOC, TXT
- Automatic text chunking for optimal retrieval
- Vector embeddings for semantic search

### ğŸ’¬ **Natural Conversation**
- Streamlit-based chat interface with design first philosophy
- Real-time streaming responses
- Context-aware conversations
- Emoji support for better readability

### ğŸ—ï¸ **Robust Architecture**
- RAG (Retrieval-Augmented Generation) pipeline
- ChromaDB for vector storage
- Ollama for local LLM inference
- Modular and extensible design

---

## ğŸ› ï¸ Installation

### Prerequisites

Before getting started, ensure you have the following installed:

- **Python 3.8+** ğŸ
- **Ollama** (for local LLM inference) ğŸ¤–
- **Homebrew** (for macOS users) ğŸº

### Step 1: Install Ollama

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows (using WSL)
curl -fsSL https://ollama.ai/install.sh | sh
```

### Step 2: Download Required Models

```bash
# Download the embedding model
ollama pull nomic-embed-text

# Download the language model
ollama pull mistral
```

### Step 3: Clone and Setup PrivateGPT

```bash
# Clone the repository
git clone https://github.com/yourusername/privateGPT.git
cd privateGPT

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Step 4: Create requirements.txt

```txt
streamlit>=1.28.0
langchain>=0.0.350
langchain-community>=0.0.10
chromadb>=0.4.15
ollama>=0.1.0
pypdf>=3.17.0
python-docx>=0.8.11
docx2txt>=0.8
```

---

## ğŸ“ Data Folder Structure

Understanding the data folder structure is crucial for setting up PrivateGPT:

```
data/
â”œâ”€â”€ raw/                    # ğŸ“„ Your unstructured documents go here
â”‚   â”œâ”€â”€ document1.pdf
â”‚   â”œâ”€â”€ report.docx
â”‚   â”œâ”€â”€ notes.txt
â”‚   â””â”€â”€ subfolder/
â”‚       â””â”€â”€ more_docs.pdf
â”œâ”€â”€ processed/              # ğŸ”§ Processed document chunks (auto-generated)
â””â”€â”€ chroma_db/             # ğŸ—„ï¸ Vector database storage (auto-generated)
    â”œâ”€â”€ chroma.sqlite3
    â””â”€â”€ index/
```

### ğŸ“‹ Setting Up Your Documents

1. **Create the data directory** (if it doesn't exist):
   ```bash
   mkdir -p data/raw
   ```

2. **Add your documents** to the `data/raw/` folder:
   - Supported formats: `.pdf`, `.docx`, `.doc`, `.txt`
   - You can organize documents in subfolders
   - No size limit (within reason)

3. **Example structure**:
   ```
   data/raw/
   â”œâ”€â”€ company_policies/
   â”‚   â”œâ”€â”€ employee_handbook.pdf
   â”‚   â””â”€â”€ code_of_conduct.docx
   â”œâ”€â”€ research_papers/
   â”‚   â”œâ”€â”€ ai_trends_2024.pdf
   â”‚   â””â”€â”€ machine_learning_guide.pdf
   â””â”€â”€ personal_notes/
       â”œâ”€â”€ meeting_notes.txt
       â””â”€â”€ project_ideas.docx
   ```

---

## ğŸš€ Usage

### Quick Start

1. **Start the services**:
   ```bash
   make start
   ```

2. **Ingest your documents**:
   ```bash
   make db-ingest
   ```

3. **Open your browser** and go to `http://localhost:8501`

4. **Start chatting** with your documents! ğŸ’¬

5. **Shut down bot**:
   ```bash
   make stop
   ```

### Available Commands

PrivateGPT comes with a comprehensive Makefile for easy management:

```bash
# ğŸ¯ Main Commands
make start          # Start all services
make stop           # Stop all services
make status         # Check service status

# ğŸ“Š Streamlit Management
make streamlit-start    # Start Streamlit app
make streamlit-stop     # Stop Streamlit app
make streamlit-reset    # Restart Streamlit

# ğŸ¤– Ollama Management
make llm-start      # Start Ollama service
make llm-stop       # Stop Ollama service
make llm-status     # Check Ollama status

# ğŸ—„ï¸ Database Management
make db-ingest      # Process and ingest documents
make db-reset       # Reset database
make db-backup      # Create database backup
make db-check       # Check database status

# ğŸ§¹ Cleanup
make clean          # Clean temporary files
make clean-all      # Deep clean everything
```

### Manual Document Ingestion

If you prefer to run the ingestion manually:

```bash
python scripts/ingest_documents.py
```

---

## ğŸ—ï¸ Architecture

PrivateGPT follows a modular RAG (Retrieval-Augmented Generation) architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“„ Documents   â”‚ â”€â”€ â”‚  ğŸ“ Ingestion   â”‚ â”€â”€ â”‚  ğŸ—„ï¸ Vector DB   â”‚
â”‚   (PDF, DOCX,   â”‚    â”‚  (Chunking &    â”‚    â”‚  (ChromaDB)    â”‚
â”‚    TXT files)   â”‚    â”‚   Embedding)    â”‚    â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¬ Streamlit   â”‚ â”€â”€ â”‚  ğŸ§  RAG         â”‚ â”€â”€ â”‚  ğŸ” Retrieval   â”‚
â”‚   Interface     â”‚    â”‚  Pipeline       â”‚    â”‚   (Semantic     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚    Search)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  ğŸ¤– Generation  â”‚
                       â”‚   (Ollama +     â”‚
                       â”‚    Mistral)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

- **ğŸ”„ Ingestion Pipeline**: Processes documents and creates vector embeddings
- **ğŸ” Retrieval System**: Finds relevant document chunks using semantic search
- **ğŸ¤– Generation Engine**: Uses Ollama with Mistral model for response generation
- **ğŸ’¬ Chat Interface**: Streamlit-based UI with real-time streaming
- **ğŸ—„ï¸ Vector Database**: ChromaDB for efficient similarity search

---

## ğŸ”§ Configuration

Customize PrivateGPT by modifying `config.py`:

```python
# Model configurations
EMBEDDING_MODEL = "nomic-embed-text"    # Change embedding model
LLM_MODEL = "mistral"                   # Change language model
OLLAMA_BASE_URL = "http://localhost:11434"

# Chunking parameters
CHUNK_SIZE = 1000                       # Adjust chunk size
CHUNK_OVERLAP = 200                     # Adjust overlap

# Retrieval parameters
TOP_K_RETRIEVAL = 5                     # Number of documents to retrieve
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **ğŸ´ Fork the repository**
2. **ğŸŒ¿ Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **ğŸ’¾ Commit your changes**: `git commit -m 'Add amazing feature'`
4. **ğŸ“¤ Push to the branch**: `git push origin feature/amazing-feature`
5. **ğŸ”„ Open a Pull Request**

### ğŸ“ Development Guidelines

- Follow PEP 8 style guidelines
- Add docstrings to all functions and classes
- Include type hints where appropriate
- Write unit tests for new features
- Update documentation as needed

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LangChain** for the RAG framework
- **Ollama** for local LLM inference
- **ChromaDB** for vector storage
- **Streamlit** for the web interface
- **Mistral** for the language model

---

<div align="center">

**ğŸ‰ Ready to chat with your documents privately?**

[Get Started](#-installation) â€¢ [View Demo](https://demo.privategpt.com) â€¢ [Join Community](https://discord.gg/privategpt)

Made with â¤ï¸ by the PrivateGPT Team

</div>